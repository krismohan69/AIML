{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Experiment_5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krismohan69/AIML/blob/master/Experiment_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "EjcpcKwppPJC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Advanced Certification in AIML\n",
        "## A Program by IIIT-H and TalentSprint"
      ]
    },
    {
      "metadata": {
        "id": "wEu7nPDCpPJF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The objective of this experiment is to understand how to apply k-fold cross-validation method on the MNIST datasets and then tune the hyper parameters of MLP Classifier."
      ]
    },
    {
      "metadata": {
        "id": "258mPttbpPJH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this experiment we will be using MNIST database. The MNIST database is a dataset of handwritten digits. It has 60,000 training samples, and 10,000 test samples. Each image is represented by 28 x 28 pixels, each containing a value 0 - 255 with its gray scale value.\n",
        "\n",
        "It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.\n",
        "\n",
        "It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting."
      ]
    },
    {
      "metadata": {
        "id": "883iWwdPpyth",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Expected time : 30mins"
      ]
    },
    {
      "metadata": {
        "id": "A9Gi0Ofj6h_9",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "b2a2d6ed-3adb-4b13-f0ab-f09a5d958cbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Experiment Explanation Video\n",
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"<video width=\"500\" height=\"300\" controls>\n",
        "  <source src=\"https://cdn.talentsprint.com/talentsprint/archives/sc/aiml/aiml_2018_blr_b6/cfus/week_8/module_2_week_8_experment_5.mp4\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video width=\"500\" height=\"300\" controls>\n",
              "  <source src=\"https://cdn.talentsprint.com/talentsprint/archives/sc/aiml/aiml_2018_blr_b6/cfus/week_8/module_2_week_8_experment_5.mp4\" type=\"video/mp4\">\n",
              "</video>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "tQvkNNTfpS2T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Setup Steps"
      ]
    },
    {
      "metadata": {
        "id": "sv8x78fVpU3M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Please enter your registration id to start: (e.g. P181900101) { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"P181901546\" #@param {type:\"string\"}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mG6_CNdepXHW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"9900255500\" #@param {type:\"string\"}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5ppOYBIoEEF3",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "eed8fc3e-e2a7-46c2-c51f-1264ffc13be1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "\n",
        "from IPython import get_ipython\n",
        "ipython = get_ipython()\n",
        "  \n",
        "notebook=\"BLR_M2W8_SAT_EXP_5\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")\n",
        "   \n",
        "   print (\"Setup completed successfully\")\n",
        "   return\n",
        "\n",
        "def submit_notebook():\n",
        "    \n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "    \n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:        \n",
        "        print(r[\"err\"])\n",
        "        return None        \n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getComplexity() and getAdditional() and getConcepts():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id, \n",
        "              \"id\" : Id, \"file_hash\" : file_hash, \"notebook\" : notebook}\n",
        "\n",
        "      r = requests.post(url, data = data)\n",
        "      print(\"Your submission is successful.\")\n",
        "      print(\"Ref Id:\", submission_id)\n",
        "      print(\"Date of submission: \", datetime.datetime.now().date().strftime(\"%d %b %Y\"))\n",
        "      print(\"Time of submission: \", datetime.datetime.now().time().strftime(\"%H:%M:%S\"))\n",
        "      print(\"View your submissions: https://iiith-aiml.talentsprint.com/notebook_submissions\")\n",
        "      print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "      return submission_id\n",
        "    else: submission_id\n",
        "    \n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if Additional: return Additional      \n",
        "    else: raise NameError('')\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "  \n",
        "def getConcepts():\n",
        "  try:\n",
        "    return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "def getId():\n",
        "  try: \n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup \n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "  \n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setup completed successfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SFzKqwLppPJI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Importing required packages\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zWoLTkutpPJN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Loading the dataset from sklearn package"
      ]
    },
    {
      "metadata": {
        "id": "d3Zg9n4zpPJO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Loading MNIST dataset from sklearn\n",
        "digits = datasets.load_digits(n_class=10)\n",
        "## Loding the data and storing in x\n",
        "X = digits.data\n",
        "## Loading the target data and storing it in y\n",
        "y = digits.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GKvy1plDpPJS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### hyper parameters\n",
        "# activation\n",
        "a = [\"identity\",\"logistic\",\"tanh\",\"relu\"]\n",
        "#solvers\n",
        "s = [\"lbfgs\",\"sgd\",\"adam\"]\n",
        "#learning rate\n",
        "lr = [0.0001,0.001,0.01,0.1]\n",
        "#hidden layers\n",
        "h = [(5,2),(3,2),(6,3),(7,2)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FKanYk0rpPJW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Applying K-Folds cross-validator\n",
        "kf = KFold(n_splits=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DqWhE0sspPJd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#function to Create MLP classifier object with hyper parameters\n",
        "def mlp(a,s,h,lr):\n",
        "    clf = MLPClassifier(activation= a ,solver= s ,hidden_layer_sizes = h,max_iter = 5000 ,learning_rate = 'constant',learning_rate_init=lr)\n",
        "    return clf  \n",
        "#function to calculate the accuracy\n",
        "def accuracy(actual,predicted):\n",
        "    return np.count_nonzero(actual == predicted)*1.0/len(actual)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JzE_gPU6pPJi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Exercise 1\n",
        "\n",
        "Predict the values using test data and calculate the accuracy"
      ]
    },
    {
      "metadata": {
        "id": "TYeKG-copPJl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1944
        },
        "outputId": "60ebadd5-1bfe-46f7-e79c-64c91644f973"
      },
      "cell_type": "code",
      "source": [
        "test_accuracy = []\n",
        "train_accuracy = []\n",
        "for i in range(10):\n",
        "    k1 = np.random.randint(0,len(a))\n",
        "    k2 = np.random.randint(0,len(s))\n",
        "    k3 = np.random.randint(0,len(lr))\n",
        "    k4 = np.random.randint(0,len(h))\n",
        "    print(\"\\nHyper-parameters = \\n activation = \", a[k1],    \"\\n solver = \", s[k2], \"\\n learning_rate_init = \", lr[k3],         \"\\n hidden_layer_sizes = \", h[k4])\n",
        "     #calling the mlp function with random hyper paramters\n",
        "    clf = mlp(a[k1],s[k2],h[k4],lr[k3])\n",
        "    tempTrain = 0\n",
        "    tempTest = 0\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        ## Splitting the data into train and test\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        Y_train, Y_test  = y[train_index], y[test_index]\n",
        "        ##fit the data into the model\n",
        "        clf.fit(X_train,Y_train)\n",
        "        ##predicting the values on the fitted model using train data\n",
        "        predTrain = clf.predict((X_train))\n",
        "        #adding the accuracy\n",
        "        tempTrain = tempTrain + accuracy(Y_train,predTrain)\n",
        "        ##predict the values on the fitted model using test data\n",
        "        predTest = clf.predict((X_test))\n",
        "        #adding the accuracy\n",
        "        tempTest = tempTest + accuracy(Y_test,predTest)\n",
        "    ##Calculating the train accuracy\n",
        "    train_accuracy.append(tempTrain*1.0/4)\n",
        "    ##Calculating the test accuracy\n",
        "    test_accuracy.append(tempTest*1.0/4)\n",
        "    print(\"(train,test) accuracy = \",tempTrain*1.0/4, tempTest*1.0/4)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Hyper-parameters = \n",
            " activation =  identity \n",
            " solver =  sgd \n",
            " learning_rate_init =  0.001 \n",
            " hidden_layer_sizes =  (3, 2)\n",
            "(train,test) accuracy =  0.731587834488775 0.6566456322692403\n",
            "\n",
            "Hyper-parameters = \n",
            " activation =  relu \n",
            " solver =  sgd \n",
            " learning_rate_init =  0.0001 \n",
            " hidden_layer_sizes =  (6, 3)\n",
            "(train,test) accuracy =  0.35077248815369466 0.3116159366493442\n",
            "\n",
            "Hyper-parameters = \n",
            " activation =  logistic \n",
            " solver =  adam \n",
            " learning_rate_init =  0.001 \n",
            " hidden_layer_sizes =  (3, 2)\n",
            "(train,test) accuracy =  0.4594901517604788 0.400617421430339\n",
            "\n",
            "Hyper-parameters = \n",
            " activation =  logistic \n",
            " solver =  adam \n",
            " learning_rate_init =  0.0001 \n",
            " hidden_layer_sizes =  (7, 2)\n",
            "(train,test) accuracy =  0.41046126241631586 0.3601373422420193\n",
            "\n",
            "Hyper-parameters = \n",
            " activation =  tanh \n",
            " solver =  sgd \n",
            " learning_rate_init =  0.01 \n",
            " hidden_layer_sizes =  (6, 3)\n",
            "(train,test) accuracy =  0.7510384104472188 0.6633828260331601\n",
            "\n",
            "Hyper-parameters = \n",
            " activation =  tanh \n",
            " solver =  sgd \n",
            " learning_rate_init =  0.1 \n",
            " hidden_layer_sizes =  (6, 3)\n",
            "(train,test) accuracy =  0.6987513740833019 0.6700210343974264\n",
            "\n",
            "Hyper-parameters = \n",
            " activation =  identity \n",
            " solver =  sgd \n",
            " learning_rate_init =  0.001 \n",
            " hidden_layer_sizes =  (6, 3)\n",
            "(train,test) accuracy =  0.8981637675987302 0.8118856718634002\n",
            "\n",
            "Hyper-parameters = \n",
            " activation =  relu \n",
            " solver =  lbfgs \n",
            " learning_rate_init =  0.001 \n",
            " hidden_layer_sizes =  (3, 2)\n",
            "(train,test) accuracy =  0.21237077008144264 0.20039346696362287\n",
            "\n",
            "Hyper-parameters = \n",
            " activation =  logistic \n",
            " solver =  sgd \n",
            " learning_rate_init =  0.01 \n",
            " hidden_layer_sizes =  (3, 2)\n",
            "(train,test) accuracy =  0.4320378123492363 0.36389507547636724\n",
            "\n",
            "Hyper-parameters = \n",
            " activation =  identity \n",
            " solver =  sgd \n",
            " learning_rate_init =  0.1 \n",
            " hidden_layer_sizes =  (3, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_base.py:91: RuntimeWarning: invalid value encountered in subtract\n",
            "  tmp = X - X.max(axis=1)[:, np.newaxis]\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
            "  return umr_maximum(a, axis, None, out, keepdims)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
            "  return umr_maximum(a, axis, None, out, keepdims)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
            "  return umr_maximum(a, axis, None, out, keepdims)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_base.py:91: RuntimeWarning: invalid value encountered in subtract\n",
            "  tmp = X - X.max(axis=1)[:, np.newaxis]\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
            "  return umr_maximum(a, axis, None, out, keepdims)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
            "  return umr_maximum(a, axis, None, out, keepdims)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
            "  return umr_maximum(a, axis, None, out, keepdims)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_base.py:91: RuntimeWarning: invalid value encountered in subtract\n",
            "  tmp = X - X.max(axis=1)[:, np.newaxis]\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
            "  return umr_maximum(a, axis, None, out, keepdims)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
            "  return umr_maximum(a, axis, None, out, keepdims)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
            "  return umr_maximum(a, axis, None, out, keepdims)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_base.py:91: RuntimeWarning: invalid value encountered in subtract\n",
            "  tmp = X - X.max(axis=1)[:, np.newaxis]\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
            "  return umr_maximum(a, axis, None, out, keepdims)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(train,test) accuracy =  0.09905364487298954 0.09905097748082159\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
            "  return umr_maximum(a, axis, None, out, keepdims)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
            "  return umr_maximum(a, axis, None, out, keepdims)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "6baqLI7VpPJr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### PLotting the data"
      ]
    },
    {
      "metadata": {
        "id": "Z_CMEv2apPJt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "d987e8fb-c1e5-48e2-deee-647ee02c7dc5"
      },
      "cell_type": "code",
      "source": [
        "##Plotting the data\n",
        "xx = np.array(range(1,11))\n",
        "plt.bar(xx-0.2,train_accuracy,width=0.2)\n",
        "plt.bar(xx, test_accuracy,width=0.2)\n",
        "plt.legend([\"Train\",\"Test\"])\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAYIcIAABj5P7r1YYfYObjGAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f94427d72b0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "skiIgURmpPJx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Applying K-Folds cross-validator\n",
        "kf = KFold(n_splits=3)\\\\#### Exercise 2\n",
        "\n",
        "Vary the number of k-fold splits and observe the changes"
      ]
    },
    {
      "metadata": {
        "id": "KR79RCav-XIn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Applying K-Folds cross-validator\n",
        "kf = KFold(n_splits=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "677BLEdKQ_Mg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#function to Create MLP classifier object with hyper parameters\n",
        "def mlp(a,s,h,lr):\n",
        "    clf = MLPClassifier(activation= a ,solver= s ,hidden_layer_sizes = h,max_iter = 10000 ,learning_rate = 'constant',learning_rate_init=lr)\n",
        "    return clf  \n",
        "#function to calculate the accuracy\n",
        "def accuracy(actual,predicted):\n",
        "    return np.count_nonzero(actual == predicted)*1.0/len(actual)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WUdoFbBI-xza",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1231
        },
        "outputId": "1cdee1d2-edd8-40d0-aa63-8c47e438df06"
      },
      "cell_type": "code",
      "source": [
        "test_accuracy = []\n",
        "train_accuracy = []\n",
        "for i in range(10):\n",
        "    k1 = np.random.randint(0,len(a))\n",
        "    k2 = np.random.randint(0,len(s))\n",
        "    k3 = np.random.randint(0,len(lr))\n",
        "    k4 = np.random.randint(0,len(h))\n",
        "    print(\"\\nHyper-parameters = \\n activation = \", a[k1],    \"\\n solver = \", s[k2], \"\\n learning_rate_init = \", lr[k3],         \"\\n hidden_layer_sizes = \", h[k4])\n",
        "     #calling the mlp function with random hyper paramters\n",
        "    clf = mlp(a[k1],s[k2],h[k4],lr[k3])\n",
        "    tempTrain = 0\n",
        "    tempTest = 0\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        ## Splitting the data into train and test\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        Y_train, Y_test  = y[train_index], y[test_index]\n",
        "        ##fit the data into the model\n",
        "        clf.fit(X_train,Y_train)\n",
        "        ##predicting the values on the fitted model using train data\n",
        "        predTrain = clf.predict((X_train))\n",
        "        #adding the accuracy\n",
        "        tempTrain = tempTrain + accuracy(Y_train,predTrain)\n",
        "        ##predict the values on the fitted model using test data\n",
        "        predTest = clf.predict((X_test))\n",
        "        #adding the accuracy\n",
        "        tempTest = tempTest + accuracy(Y_test,predTest)\n",
        "    ##Calculating the train accuracy\n",
        "    train_accuracy.append(tempTrain*1.0/5)\n",
        "    ##Calculating the test accuracy\n",
        "    test_accuracy.append(tempTest*1.0/5)\n",
        "    print(\"(train,test) accuracy = \",tempTrain*1.0/3, tempTest*1.0/3)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Hyper-parameters = \n",
            " activation =  tanh \n",
            " solver =  adam \n",
            " learning_rate_init =  0.1 \n",
            " hidden_layer_sizes =  (5, 2)\n",
            "(train,test) accuracy =  0.3553144129104062 0.3350027824151363\n",
            "\n",
            "Hyper-parameters = \n",
            " activation =  identity \n",
            " solver =  lbfgs \n",
            " learning_rate_init =  0.01 \n",
            " hidden_layer_sizes =  (5, 2)\n",
            "(train,test) accuracy =  0.8235948803561491 0.7200890372843629\n",
            "\n",
            "Hyper-parameters = \n",
            " activation =  identity \n",
            " solver =  adam \n",
            " learning_rate_init =  0.01 \n",
            " hidden_layer_sizes =  (6, 3)\n",
            "(train,test) accuracy =  0.9318308291597107 0.8085698386199222\n",
            "\n",
            "Hyper-parameters = \n",
            " activation =  logistic \n",
            " solver =  adam \n",
            " learning_rate_init =  0.001 \n",
            " hidden_layer_sizes =  (6, 3)\n",
            "(train,test) accuracy =  0.9493600445186422 0.7679465776293822\n",
            "\n",
            "Hyper-parameters = \n",
            " activation =  relu \n",
            " solver =  adam \n",
            " learning_rate_init =  0.0001 \n",
            " hidden_layer_sizes =  (3, 2)\n",
            "(train,test) accuracy =  0.4181969949916528 0.38452977184195886\n",
            "\n",
            "Hyper-parameters = \n",
            " activation =  relu \n",
            " solver =  lbfgs \n",
            " learning_rate_init =  0.01 \n",
            " hidden_layer_sizes =  (7, 2)\n",
            "(train,test) accuracy =  0.343906510851419 0.28937117417918756\n",
            "\n",
            "Hyper-parameters = \n",
            " activation =  tanh \n",
            " solver =  sgd \n",
            " learning_rate_init =  0.001 \n",
            " hidden_layer_sizes =  (3, 2)\n",
            "(train,test) accuracy =  0.3383416805787423 0.3099610461880912\n",
            "\n",
            "Hyper-parameters = \n",
            " activation =  relu \n",
            " solver =  lbfgs \n",
            " learning_rate_init =  0.0001 \n",
            " hidden_layer_sizes =  (6, 3)\n",
            "(train,test) accuracy =  0.4079020589872009 0.3789649415692821\n",
            "\n",
            "Hyper-parameters = \n",
            " activation =  relu \n",
            " solver =  sgd \n",
            " learning_rate_init =  0.1 \n",
            " hidden_layer_sizes =  (5, 2)\n",
            "(train,test) accuracy =  0.10239287701725097 0.09961046188091265\n",
            "\n",
            "Hyper-parameters = \n",
            " activation =  logistic \n",
            " solver =  adam \n",
            " learning_rate_init =  0.01 \n",
            " hidden_layer_sizes =  (7, 2)\n",
            "(train,test) accuracy =  0.5762381747356705 0.5052865887590429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rgymX3hOphVj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Please answer the questions below to complete the experiment:"
      ]
    },
    {
      "metadata": {
        "id": "ZUD27jBgpPJz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"Good and Challenging me\" #@param [\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KJw1jBtxplns",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title If it was very easy, what more you would have liked to have been added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"test\" #@param {type:\"string\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dbgppxZ1pnTD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"Yes\" #@param [\"Yes\", \"No\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "97hl2G5Ipoyd",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "46b78684-b5cd-46a1-dacb-126ff5571beb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id =return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your submission is successful.\n",
            "Ref Id: 8336\n",
            "Date of submission:  05 Jan 2019\n",
            "Time of submission:  12:47:59\n",
            "View your submissions: https://iiith-aiml.talentsprint.com/notebook_submissions\n",
            "For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pktokhHkau44",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}